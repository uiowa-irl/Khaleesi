{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import utilities\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "import re\n",
    "from urllib import parse as URLparse\n",
    "from openwpm_utils import domain as du\n",
    "import base64\n",
    "import hashlib\n",
    "from collections import OrderedDict\n",
    "from prettytable import PrettyTable\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = 'khaleesi/data/'\n",
    "\n",
    "non_interactive_http_dir = base_directory + 'crawl-http-labeled.json'\n",
    "non_interactive_js_dir = base_directory + 'crawl-js-connected-labeled.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_chains = utilities.read_json(non_interactive_http_dir)\n",
    "js_chains = utilities.read_json(non_interactive_js_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function for getting identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier_cookies(cookie_string, cookie_length = 8):\n",
    "    cookie_set = set()\n",
    "    \n",
    "    for cookie in cookie_string.split('\\n'):\n",
    "        cookie = cookie.split(';')[0]\n",
    "        if cookie.count('=') >= 1:\n",
    "            cookie = cookie.split('=', 1)\n",
    "            cookie_set |= set(re.split('[^a-zA-Z0-9_=-]', cookie[1]))\n",
    "            cookie_set.add(cookie[0])\n",
    "        else:\n",
    "            cookie_set |= set(re.split('[^a-zA-Z0-9_=-]', cookie))\n",
    "    \n",
    "#     remove cookies with length < 8 \n",
    "    cookie_set = set([s for s in list(cookie_set) if len(s) >= cookie_length])\n",
    "    return cookie_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers_from_qs(url, qs_item_length = 8):\n",
    "    qs = URLparse.parse_qsl(URLparse.urlsplit(url).query)\n",
    "    qs_set = set()\n",
    "    \n",
    "    for item in qs:\n",
    "        qs_set |= set(re.split('[^a-zA-Z0-9_=-]', item[0]))\n",
    "        qs_set |= set(re.split('[^a-zA-Z0-9_=-]', item[1]))\n",
    "        \n",
    "    qs_set = set([s for s in list(qs_set) if len(s) >= qs_item_length])\n",
    "    return qs_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers_from_uncommon_headers(header_prop, item_length = 8):\n",
    "    splitted_header_prop_set = set()\n",
    "\n",
    "    splitted_header_prop = set(re.split('[^a-zA-Z0-9_=-]', header_prop))\n",
    "    splitted_header_prop_set = set([s for s in list(splitted_header_prop) if len(s) >= item_length])\n",
    "    return splitted_header_prop_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_or_hostname(url):\n",
    "    # we stop if we cannot retrieve the domain or hostanmes\n",
    "    # we won't be able to link domains/hostnames if they are empty or unavailable  \n",
    "    current_domain_or_hostname = du.get_ps_plus_1(url)\n",
    "    \n",
    "    if current_domain_or_hostname == '' or current_domain_or_hostname == None:\n",
    "        current_domain_or_hostname = du.urlparse(url).hostname\n",
    "        if current_domain_or_hostname == '' or current_domain_or_hostname == None:\n",
    "            return False, ''\n",
    "    \n",
    "    return True, current_domain_or_hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_http_headers = set()\n",
    "known_http_headers_raw = utilities.read_file_newline_stripped('common_headers.txt')\n",
    "for item in known_http_headers_raw:\n",
    "    if item.strip() != '':\n",
    "        known_http_headers.add(item.strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_csync_events(identifiers, next_identifiers, key, current_domain_or_hostname, next_url, csync_domains):\n",
    "    for identifier in identifiers:    \n",
    "        next_domain_or_hostname = get_domain_or_hostname(next_url)\n",
    "        if not next_domain_or_hostname[0]:\n",
    "            break\n",
    "\n",
    "        next_domain_or_hostname = next_domain_or_hostname[1]\n",
    "        domain_domain = current_domain_or_hostname + '|' + next_domain_or_hostname\n",
    "        \n",
    "        if domain_domain not in csync_domains:\n",
    "            csync_domains[domain_domain] = {}\n",
    "            csync_domains[domain_domain]['chains'] = []\n",
    "            csync_domains[domain_domain]['b64_chains'] = []\n",
    "            csync_domains[domain_domain]['md5_chains'] = []\n",
    "            csync_domains[domain_domain]['sha1_chains'] = []\n",
    "        \n",
    "        base64_identifier = base64.b64encode(identifier.encode('utf-8')).decode('utf8')\n",
    "        md5_identifier = hashlib.md5(identifier.encode('utf-8')).hexdigest()\n",
    "        sha1_identifier = hashlib.sha1(identifier.encode('utf-8')).hexdigest()\n",
    "        \n",
    "        if identifier in next_url or identifier in next_identifiers:\n",
    "            csync_domains[domain_domain]['chains'].append({'chain': key, 'identifier': identifier})\n",
    "        elif base64_identifier in next_url or base64_identifier in next_identifiers:\n",
    "            csync_domains[domain_domain]['b64_chains'].append({'chain':key, 'identifier': identifier, 'encoded': base64_identifier})\n",
    "        elif md5_identifier in next_url or md5_identifier in next_identifiers:\n",
    "            csync_domains[domain_domain]['md5_chains'].append({'chain':key, 'identifier': identifier, 'encoded': md5_identifier})\n",
    "        elif sha1_identifier in next_url or sha1_identifier in next_identifiers:\n",
    "            csync_domains[domain_domain]['sha1_chains'].append({'chain':key, 'identifier': identifier, 'encoded': sha1_identifier})\n",
    "            \n",
    "    return csync_domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cookie syncing identification code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_csync_heuristic(json_representation, known_http_headers, csync_domains):\n",
    "    pbar = tqdm(total=len(json_representation), position=0, leave=True)\n",
    "    for key in json_representation:\n",
    "        pbar.update(1)\n",
    "\n",
    "        for idx, item in enumerate(json_representation[key]['content']):\n",
    "            current_url = item['url']\n",
    "            current_referrer = item['referrer']\n",
    "            current_identifiers = set()\n",
    "\n",
    "            current_domain_or_hostname = get_domain_or_hostname(current_url)\n",
    "            if not current_domain_or_hostname[0]:\n",
    "                continue\n",
    "\n",
    "            current_domain_or_hostname = current_domain_or_hostname[1]\n",
    "\n",
    "            sent_cookies = ''\n",
    "            for s_item in item['request_headers']:\n",
    "                if s_item[0].lower() == 'cookie':\n",
    "                    current_identifiers |= get_identifier_cookies(s_item[1])\n",
    "                if s_item[0].lower() not in known_http_headers:\n",
    "                    current_identifiers |= get_identifiers_from_uncommon_headers(s_item[1])\n",
    "\n",
    "\n",
    "            recieved_cookies = ''\n",
    "            for s_item in item['response_headers']:\n",
    "                if s_item[0].lower() == 'set-cookie':\n",
    "                    current_identifiers |= get_identifier_cookies(s_item[1])\n",
    "                if s_item[0].lower() not in known_http_headers:\n",
    "                    current_identifiers |= get_identifiers_from_uncommon_headers(s_item[1])\n",
    "\n",
    "\n",
    "            current_identifiers |= get_identifiers_from_qs(current_url)\n",
    "            current_identifiers |= get_identifiers_from_qs(current_referrer)\n",
    "\n",
    "    \n",
    "            if key.startswith('J|'):\n",
    "                end = len(json_representation[key]['content'])\n",
    "            else:\n",
    "                end = idx + 2\n",
    "                if end > len(json_representation[key]['content']):\n",
    "                    continue\n",
    "\n",
    "            for item_1 in json_representation[key]['content'][idx+1:end]:\n",
    "                next_url = item_1['url']\n",
    "                next_headers = item_1['request_headers']\n",
    "\n",
    "                next_identifiers = set()\n",
    "                for s_item in next_headers:\n",
    "                    if s_item[0].lower() == 'cookie':\n",
    "                        next_identifiers |= get_identifier_cookies(s_item[1])\n",
    "                    if s_item[0].lower() not in known_http_headers:\n",
    "                        next_identifiers |= get_identifiers_from_uncommon_headers(s_item[1])\n",
    "\n",
    "\n",
    "                csync_domains = check_csync_events(current_identifiers, next_identifiers, key, current_domain_or_hostname, next_url, csync_domains)\n",
    "    return csync_domains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_csync = {}\n",
    "current_csync = run_csync_heuristic(http_chains, known_http_headers, results_dict, current_csync)\n",
    "current_csync = run_csync_heuristic(js_chains, known_http_headers, results_dict, current_csync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up cysnc events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cysnc_clean_up(csync_domains):\n",
    "    to_delete = set()\n",
    "    for domain_domain in csync_domains:\n",
    "        if len(csync_domains[domain_domain]['chains']) == 0 and \\\n",
    "            len(csync_domains[domain_domain]['b64_chains']) == 0 and \\\n",
    "            len(csync_domains[domain_domain]['md5_chains']) == 0 and \\\n",
    "            len(csync_domains[domain_domain]['sha1_chains']) == 0:\n",
    "            to_delete.add(domain_domain)\n",
    "    for key in to_delete:\n",
    "        del csync_domains[key]\n",
    "    return csync_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(current_csync))\n",
    "current_csync = cysnc_clean_up(current_csync)\n",
    "print(len(current_csync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for cookie syncing statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_csync_events(_from, _to, sending_json_obj, receiving_json_obj):\n",
    "    if _from not in sending_json_obj:\n",
    "        sending_json_obj[_from] = {}\n",
    "        sending_json_obj[_from]['count'] = 1\n",
    "        sending_json_obj[_from]['domains'] = set({_to})\n",
    "    else:    \n",
    "        sending_json_obj[_from]['count'] += 1\n",
    "        sending_json_obj[_from]['domains'].add(_to)\n",
    "\n",
    "    if _to not in receiving_json_obj:\n",
    "        receiving_json_obj[_to] = {}\n",
    "        receiving_json_obj[_to]['count'] = 1\n",
    "        receiving_json_obj[_to]['domains'] = set({_from})\n",
    "    else:\n",
    "        receiving_json_obj[_to]['count'] += 1\n",
    "        receiving_json_obj[_to]['domains'].add(_from)\n",
    "            \n",
    "    return sending_json_obj, receiving_json_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csynced_chains(chains, chains_synced):\n",
    "    for item in chains:\n",
    "        if item['chain'] not in chains_synced:\n",
    "            chains_synced[item['chain']] = {}\n",
    "            chains_synced[item['chain']]['count'] = 1\n",
    "        else:\n",
    "            chains_synced[item['chain']]['count'] += 1\n",
    "#         break\n",
    "    return chains_synced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_domains_in_chains(json_representation, khaleesi_detections):\n",
    "    all_domains = set()\n",
    "    for key in json_representation:\n",
    "\n",
    "        if key not in khaleesi_detections:\n",
    "            continue\n",
    "\n",
    "        for idx, item in enumerate(json_representation[key]['content']):\n",
    "            current_domain_or_hostname = get_domain_or_hostname(item['url'])\n",
    "\n",
    "            if not current_domain_or_hostname[0]:\n",
    "                continue\n",
    "\n",
    "            all_domains.add(current_domain_or_hostname[1])\n",
    "    return all_domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding cookie syncing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_csync_stats(csync_domains, no_of_chains, no_of_domains):\n",
    "    all_domains = set()\n",
    "\n",
    "    sending_to = {}\n",
    "    recieved_from = {}\n",
    "\n",
    "    b64_sending_to = {}\n",
    "    b64_recieved_from = {}\n",
    "    md5_sending_to = {}\n",
    "    md5_recieved_from = {}\n",
    "    sha1_sending_to = {}\n",
    "    sha1_recieved_from = {}\n",
    "\n",
    "    chains_synced_simple = {}\n",
    "    chains_synced_b64 = {}\n",
    "    chains_synced_md5 = {}\n",
    "    chains_synced_sha1 = {}\n",
    "\n",
    "    for domain_domain in csync_domains:\n",
    "        _from = domain_domain.split('|')[0]\n",
    "        _to = domain_domain.split('|')[1]\n",
    "        \n",
    "        if _from == _to:\n",
    "            continue\n",
    "\n",
    "        if len(csync_domains[domain_domain]['chains']) > 0:\n",
    "            sending_to, recieved_from = count_csync_events(_from, _to, sending_to, recieved_from)\n",
    "            chains_synced_simple = get_csynced_chains(csync_domains[domain_domain]['chains'], chains_synced_simple)\n",
    "\n",
    "        if len(csync_domains[domain_domain]['b64_chains']) > 0:\n",
    "            sending_to, recieved_from = count_csync_events(_from, _to, sending_to, recieved_from)\n",
    "            b64_sending_to, b64_recieved_from = count_csync_events(_from, _to, b64_sending_to, b64_recieved_from)\n",
    "            chains_synced_b64 = get_csynced_chains(csync_domains[domain_domain]['b64_chains'], chains_synced_b64)\n",
    "\n",
    "        if len(csync_domains[domain_domain]['md5_chains']) > 0:\n",
    "            sending_to, recieved_from = count_csync_events(_from, _to, sending_to, recieved_from)\n",
    "            md5_sending_to, md5_recieved_from = count_csync_events(_from, _to, md5_sending_to, md5_recieved_from)\n",
    "            chains_synced_md5 = get_csynced_chains(csync_domains[domain_domain]['md5_chains'], chains_synced_md5)\n",
    "\n",
    "        if len(csync_domains[domain_domain]['sha1_chains']) > 0:\n",
    "            sending_to, recieved_from = count_csync_events(_from, _to, sending_to, recieved_from)\n",
    "            sha1_sending_to, sha1_recieved_from = count_csync_events(_from, _to, sha1_sending_to, sha1_recieved_from)\n",
    "            chains_synced_sha1 = get_csynced_chains(csync_domains[domain_domain]['sha1_chains'], chains_synced_sha1)\n",
    "    \n",
    "    \n",
    "    # csync domain statistics\n",
    "    csync_domains = set(sending_to.keys()).union(set(recieved_from.keys())).\\\n",
    "                        union(set(b64_sending_to.keys())).union(set(b64_recieved_from.keys())).\\\n",
    "                        union(set(md5_sending_to.keys())).union(set(md5_recieved_from.keys())).\\\n",
    "                        union(set(sha1_sending_to.keys())).union(set(sha1_recieved_from.keys()))\n",
    "\n",
    "\n",
    "    # csync chain statistics\n",
    "    csync_chains = set(chains_synced_simple.keys()).union(set(chains_synced_b64.keys()))\\\n",
    "                            .union(set(chains_synced_md5.keys()))\\\n",
    "                            .union(set(chains_synced_sha1.keys()))\n",
    "\n",
    "\n",
    "    # csync encoded chain statistics\n",
    "    csync_encoded = set(b64_sending_to.keys()).union(set(b64_recieved_from.keys()))\\\n",
    "                    .union(set(md5_sending_to.keys())).union(set(md5_recieved_from.keys()))\\\n",
    "                    .union(set(sha1_sending_to.keys())).union(set(sha1_recieved_from.keys()))\n",
    "    \n",
    "    # encoded cookie syncing stats can also be returned\n",
    "    return csync_domains, sending_to, recieved_from  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csync_domains, sending_to, recieved_from = compute_csync_stats(current_csync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print top csync domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(json_obj, count_limit = 20):\n",
    "    count = 0\n",
    "    t = PrettyTable(['Domains', 'Csync count'])\n",
    "    for key in json_obj:\n",
    "        count += 1\n",
    "        if count <= count_limit:\n",
    "            t.add_row([key, json_obj[key]['count']])\n",
    "            \n",
    "    print(t)\n",
    "    \n",
    "def average_sharing(syncing_domains):\n",
    "    total = 0\n",
    "    for key in syncing_domains:\n",
    "        total += syncing_domains[key]['count']\n",
    "    print(total / len(syncing_domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_csyncs(sending_to, recieved_from):\n",
    "    sending_to_sorted = OrderedDict(sorted(sending_to.items(), key=lambda k: k[1]['count'], reverse=True))\n",
    "    recieved_from_sorted = OrderedDict(sorted(recieved_from.items(), key=lambda k: k[1]['count'], reverse=True))\n",
    "    \n",
    "    print_table(sending_to_sorted)\n",
    "    average_sharing(sending_to)\n",
    "\n",
    "    print_table(recieved_from_sorted)\n",
    "    average_sharing(recieved_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_csyncs(sending_to, recieved_from)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
